{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Graph:\n",
        "    def __init__(self, graph_dict=None):\n",
        "        if graph_dict is None:\n",
        "            graph_dict = {}\n",
        "        self.graph = graph_dict\n",
        "\n",
        "    def addEdge(self, u, v):\n",
        "        if u not in self.graph:\n",
        "            self.graph[u] = []\n",
        "        if v not in self.graph:\n",
        "            self.graph[v] = []\n",
        "        self.graph[u].append(v)\n",
        "        self.graph[v].append(u)\n",
        "\n",
        "    def contractEdge(self, u, v):\n",
        "        # Merge v into u\n",
        "        for node in self.graph[v]:\n",
        "            if node != u:\n",
        "                self.graph[u].append(node)\n",
        "            self.graph[node].remove(v)\n",
        "            if node != u:\n",
        "                self.graph[node].append(u)\n",
        "        del self.graph[v]\n",
        "\n",
        "        # Remove nodes with no neighbors\n",
        "        for key in list(self.graph.keys()):\n",
        "            if not self.graph[key]:\n",
        "                del self.graph[key]\n",
        "\n",
        "    def kargerMinCut(self):\n",
        "        while len(self.graph) > 2:\n",
        "            u = random.choice(list(self.graph.keys()))\n",
        "            v = random.choice(self.graph[u])\n",
        "            self.contractEdge(u, v)\n",
        "        min_cut = len(self.graph[list(self.graph.keys())[0]])\n",
        "        return min_cut\n",
        "\n",
        "def karger(graph):\n",
        "    min_cut = float('inf')\n",
        "    for _ in range(len(graph.graph)**2):\n",
        "        current_cut = Graph(graph.graph).kargerMinCut()\n",
        "        min_cut = min(min_cut, current_cut)\n",
        "    return min_cut\n",
        "\n",
        "# Test\n",
        "g = Graph()\n",
        "g.addEdge(0, 1)\n",
        "g.addEdge(0, 2)\n",
        "g.addEdge(1, 2)\n",
        "g.addEdge(1, 3)\n",
        "g.addEdge(2, 3)\n",
        "\n",
        "print(\"Minimum cut:\", karger(g))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmHaEKBYDV9Z",
        "outputId": "c6a3b9fb-cbb2-440a-f123-f850a1d8d876"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum cut: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RusiwTQWDU39",
        "outputId": "597cb220-499a-4b8a-ed86-0ec38872c71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the desired cache size: 5\n",
            "FIFO Cache misses: 512\n",
            "LRU Cache misses: 485\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "class Cache:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.cache = []\n",
        "        self.history = []  # For tracking the state of the cache\n",
        "\n",
        "    def add_to_history(self):\n",
        "        self.history.append(list(self.cache))\n",
        "\n",
        "class FIFO(Cache):\n",
        "    def access(self, item):\n",
        "        if item not in self.cache:\n",
        "            if len(self.cache) == self.size:\n",
        "                self.cache.pop(0)\n",
        "            self.cache.append(item)\n",
        "        self.add_to_history()\n",
        "\n",
        "class LRU(Cache):\n",
        "    def access(self, item):\n",
        "        if item in self.cache:\n",
        "            self.cache.remove(item)\n",
        "        elif len(self.cache) == self.size:\n",
        "            self.cache.pop(0)\n",
        "        self.cache.append(item)\n",
        "        self.add_to_history()\n",
        "\n",
        "def main():\n",
        "    # Randomly generate 1000 integers from 0 to 9\n",
        "    data = [random.randint(0, 9) for _ in range(1000)]\n",
        "\n",
        "    cache_size = int(input(\"Enter the desired cache size: \"))\n",
        "\n",
        "    fifo_cache = FIFO(cache_size)\n",
        "    lru_cache = LRU(cache_size)\n",
        "\n",
        "    for item in data:\n",
        "        fifo_cache.access(item)\n",
        "        lru_cache.access(item)\n",
        "\n",
        "    fifo_misses = len(fifo_cache.history) - sum([1 for state in fifo_cache.history if item in state])\n",
        "    lru_misses = len(lru_cache.history) - sum([1 for state in lru_cache.history if item in state])\n",
        "\n",
        "    print(f\"FIFO Cache misses: {fifo_misses}\")\n",
        "    print(f\"LRU Cache misses: {lru_misses}\")\n",
        "\n",
        "    # Uncomment if you want to see the cache history\n",
        "    # print(\"FIFO cache history:\", fifo_cache.history)\n",
        "    # print(\"LRU cache history:\", lru_cache.history)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}